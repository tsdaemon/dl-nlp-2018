{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Specific Neural Architectures for NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Yuriy Guts_**\n",
    "\n",
    "_UCU NLP Summer School, 2018_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "By now, you have a decent arsenal of approaches for building machine learning models for NLP. However, as far as the models go, we've mainly used general-purpose classification architectures so far. Even in the case of feed-forward neural networks (MLP) there's nothing architecturally tailored for handling language data or sequential data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the following phrase. What would be the BoW vector for it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "_I liked the new LG phone but it was not just as good as the one from Samsung_\n",
    "<img src=\"bow-and-word-order.png\">\n",
    "<center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature vector can be directly used for many traditional models, but does it capture subtle language details like word order and regularities?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today we are going to explore some neural architectures that are more specialized for handling language: 1D **convolutional neural networks** (CNN) and **recurrent neural networks** (RNN)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the architectures we'll explore are primarily used as feature extractors according to the neural NLP diagram below (source: [explosion.ai](https://explosion.ai/blog/deep-learning-formula-nlp)):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"embed-encode-attend-predict.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When thinking about CNNs, RNNs or other approaches it is useful to think about them as \"Lego Bricks\" that can be mixed and matched to create a desired structure and to achieve the desired behavior. This allows us to create large and elaborate network structures, with multiple layers of MLPs, CNNs and RNNs feeding into each other, and training the entire network in an end-to-end fashion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Convolutional Neural Networks\n",
    "\n",
    "#### _AKA: \"Learnable N-gram Detectors\"_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often we are interested in making predictions based on **ordered** sets of items:\n",
    "    \n",
    "* sequence of characters in a word\n",
    "* sequence of words in a sentence\n",
    "* sequence of sentences in a document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A typical example is sentiment analysis where we want to predict the emotional background of a phrase. Some of the sentence words can be very informative of the sentiment, but let's look at our earlier example again:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "_I liked the new LG phone but it was not just as good as the one from Samsung._\n",
    "<center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is difficult for a non-language-aware model to capture that the writer actually considered the first phone to be inferior to the other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you probably know, a slightly better option in this case would be to include combinations of words (n-grams) in the bag-of-words model. That is, we allocate separate dimensions for _I liked the_, _liked the new_, _the new LG_ and so on.\n",
    "\n",
    "That way, _good_ and _not as good_ would have a different meaning for the model. However, a downside of this approach is that it results in huge matrices, will not scale for longer ngrams (typically longer than 4-5), and extreme sparsity will lead to ill-defined statistical strength of the features. For example, \"_really loved the new phone_\" and \"_genuinely enjoyed the new phone_\" have a very similar meaning but it's highly improbable to see both exact phrases even in a fairly large corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **convolution-and-pooling network** is designed to identify indicative local predictors in a large structure, and combine them into a fixed size vector representation of the structure, capturing the local aspects that are valuable for the prediction task at hand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main idea is to apply a non-linear learned function over each $k$-word sliding window over the sequence.\n",
    "\n",
    "Let's define the operator $\\oplus(w_{i:i+k-1})$ to be the concatenation of vectors $w_i, w_{i+1}, ..., w_{i+k-1}$.\n",
    "\n",
    "The concatenated vector of the $i$-th window is $x_i = \\oplus(w_{i:i+k-1}) = [w_i; w_{i+1}; ...; w_{i+k-1}]$.\n",
    "\n",
    "We then apply the convolution filter to each window vector $x_i$, resulting in _scalar_ values $p_i$:\n",
    "\n",
    "$$\n",
    "p_i = g(x_i \\cdot u) \\\\\n",
    "x_i = \\oplus(w_{i:i-k+1}) \\\\\n",
    "p_i \\in \\mathbb{R} \\quad x_i \\in \\mathbb{R}^{k \\cdot d_{emb}} \\quad u \\in \\mathbb{R}^{k \\cdot d_{emb}}\n",
    "$$\n",
    "\n",
    "Where $g$ is a nonlinear activation function like $tahn$, $ReLU$ etc. and $u$ is a learnable weight vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is customary to use $\\ell$ different filters $u_1, ... u_{\\ell}$ which can be arranged into a matrix $U$, and a bias vector $b$ is often added:\n",
    "\n",
    "$$\n",
    "p_i g(x_i \\cdot U + b) \\\\\n",
    "p_i \\in \\mathbb{R}^\\ell \\quad x_i \\in \\mathbb{R}^{k \\cdot d_{emb}} \\quad U \\in \\mathbb{R}^{k \\cdot d_{emb} \\times \\ell} \\quad b \\in \\mathbb{R}^\\ell \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also vary the sizes of filters ($k$) to obtain features from $k$-grams of different length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, graphically (source: [WildML](http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/)): <img src=\"word-cnn.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import spacy\n",
    "\n",
    "np.set_printoptions(formatter={'float': '{: 0.5f}'.format})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make sure to run `python -m spacy download en_core_web_md` if you've just installed spacy.\n",
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: I\tFirst 3 embedding dims: [ 0.18733  0.40595 -0.51174]\n",
      "Token: like\tFirst 3 embedding dims: [-0.18417  0.05511 -0.36953]\n",
      "Token: this\tFirst 3 embedding dims: [-0.08760  0.35502  0.06387]\n",
      "Token: movie\tFirst 3 embedding dims: [ 0.20710 -0.47656  0.15479]\n",
      "Token: very\tFirst 3 embedding dims: [-0.31342  0.37267 -0.41600]\n",
      "Token: much\tFirst 3 embedding dims: [-0.40534  0.47027 -0.06660]\n",
      "Token: !\tFirst 3 embedding dims: [-0.26554  0.33531  0.21860]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp('I like this movie very much!')\n",
    "for token in doc:\n",
    "    print('Token: {}\\tFirst 3 embedding dims: {}'.format(token, token.vector[:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document tensor shape: (7, 300)\n"
     ]
    }
   ],
   "source": [
    "doc_matrix = np.vstack(token.vector for token in doc)\n",
    "print('Document tensor shape:', doc_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-gram filter #0 shape: (2, 300)\n",
      "2-gram filter #1 shape: (2, 300)\n",
      "3-gram filter #0 shape: (3, 300)\n",
      "3-gram filter #1 shape: (3, 300)\n",
      "4-gram filter #0 shape: (4, 300)\n",
      "4-gram filter #1 shape: (4, 300)\n"
     ]
    }
   ],
   "source": [
    "conv_sizes = [2, 3, 4]\n",
    "conv_filters_per_size = 2\n",
    "\n",
    "# Initialize each filter weights randomly.\n",
    "# We'll use 'i', 'k', 'l' names to match the notation above.\n",
    "\n",
    "conv_filter_weights = {\n",
    "    k: [\n",
    "        np.random.uniform(size=(k, doc_matrix.shape[1]))\n",
    "        for l in range(conv_filters_per_size)\n",
    "    ]\n",
    "    for k in conv_sizes\n",
    "}\n",
    "\n",
    "for k in conv_sizes:\n",
    "    for l in range(conv_filters_per_size):\n",
    "        print('{}-gram filter #{} shape: {}'.format(k, l, conv_filter_weights[k][l].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2-gram filter #0: convolving I,like\n",
      "2-gram filter #0: convolving like,this\n",
      "2-gram filter #0: convolving this,movie\n",
      "2-gram filter #0: convolving movie,very\n",
      "2-gram filter #0: convolving very,much\n",
      "2-gram filter #0: convolving much,!\n",
      "2-gram filter #1: convolving I,like\n",
      "2-gram filter #1: convolving like,this\n",
      "2-gram filter #1: convolving this,movie\n",
      "2-gram filter #1: convolving movie,very\n",
      "2-gram filter #1: convolving very,much\n",
      "2-gram filter #1: convolving much,!\n",
      "\n",
      "3-gram filter #0: convolving I,like,this\n",
      "3-gram filter #0: convolving like,this,movie\n",
      "3-gram filter #0: convolving this,movie,very\n",
      "3-gram filter #0: convolving movie,very,much\n",
      "3-gram filter #0: convolving very,much,!\n",
      "3-gram filter #1: convolving I,like,this\n",
      "3-gram filter #1: convolving like,this,movie\n",
      "3-gram filter #1: convolving this,movie,very\n",
      "3-gram filter #1: convolving movie,very,much\n",
      "3-gram filter #1: convolving very,much,!\n",
      "\n",
      "4-gram filter #0: convolving I,like,this,movie\n",
      "4-gram filter #0: convolving like,this,movie,very\n",
      "4-gram filter #0: convolving this,movie,very,much\n",
      "4-gram filter #0: convolving movie,very,much,!\n",
      "4-gram filter #1: convolving I,like,this,movie\n",
      "4-gram filter #1: convolving like,this,movie,very\n",
      "4-gram filter #1: convolving this,movie,very,much\n",
      "4-gram filter #1: convolving movie,very,much,!\n",
      "\n",
      "2-gram filter #0 output: [ 0.00000  1.14685  0.00000  0.00000  0.00000  2.66378]\n",
      "2-gram filter #1 output: [ 0.00000  5.46360  0.60463  0.00000  0.00000  3.00685]\n",
      "\n",
      "3-gram filter #0 output: [ 0.00000  0.00000  0.00000  0.00000  0.00000]\n",
      "3-gram filter #1 output: [ 1.48743  3.58260  0.00000  0.00000  1.15202]\n",
      "\n",
      "4-gram filter #0 output: [ 1.57274  0.00000  0.00000  1.38235]\n",
      "4-gram filter #1 output: [ 1.77907  0.00000  0.00000  1.79792]\n"
     ]
    }
   ],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(x, 0)\n",
    "\n",
    "# Convolve the input document using different filters.\n",
    "# This code isn't efficient, mainly written for clarity.\n",
    "conv_filter_outputs = {}\n",
    "\n",
    "for k in conv_sizes:\n",
    "    print()\n",
    "    conv_filter_outputs[k] = [list() for l in range(conv_filters_per_size)]\n",
    "    \n",
    "    for l in range(conv_filters_per_size):\n",
    "        for i in range(len(doc_matrix) - k + 1):\n",
    "            tokens = [doc[t].text for t in range(i, i + k)]\n",
    "            print('{}-gram filter #{}: convolving {}'.format(k, l, ','.join(tokens)))\n",
    "\n",
    "            convolution = relu(np.sum(conv_filter_weights[k][l] * doc_matrix[i:i + k]))\n",
    "            conv_filter_outputs[k][l].append(convolution)\n",
    "\n",
    "        conv_filter_outputs[k][l] = np.array(conv_filter_outputs[k][l])\n",
    "\n",
    "for k in conv_sizes:\n",
    "    print()\n",
    "    for l in range(conv_filters_per_size):\n",
    "        print('{}-gram filter #{} output: {}'.format(k, l, conv_filter_outputs[k][l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we've computed the convolutions over all possible windows in the sentence, we apply a \"pooling\" operation to combine the vectors resulting from different windows into a single $\\ell$-dimensional vector, usually by taking the max or the average value in each of the $\\ell$ dimensions over the different windows.\n",
    "\n",
    "The intention is to focus on the features that activate the receptive unit the most, regardless of their exact location. Each filter extracts a different indicator, and the pooling operation \"zooms in\" on the most important ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another variation is the $k$-max pooling operation, in which the top $k$ values in each dimension are retained instead of only the best one, while preserving the order in which they appeared in the text. This pooling operation produces a $k \\times \\ell$ matrix which can be later reshaped into a vector. Yet another variation is dynamic pooling where we divide the sequence into parts along the time axis and pool each part separately.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 1D convolution approach described so far can be thought of as an $n$-gram detector. A convolution layer with a window of size $k$ is learning to identify indicative $k$-grams in the input.\n",
    "\n",
    "The approach can be extended into a hierarchy of convolutional layers, in which a sequence of convolution layers are applied one after the other. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"cnn-hierarchical.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding, channels, strides, dilations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common question for CNNs: what should we do on the document boundaries? Should we allow the filter to cross the boundary and apply some sort of padding like we often do with images? The answer is we can do both. The approaches without padding and with padding are called **narrow** and **wide** convolutions respectively. If we apply padding, we can either pad with zeros or allocate a special padding word in our dictionary with its own embedding vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"cnn-padding.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In computer vision, a picture is represented as a collection of pixels, each representing the color intensity of a particular point. When using an RGB color scheme, each pixel is a combination of three intensity values—one for each of the Red, Green, and Blue components. These are then stored in three different matrices. Each matrix provides a different “view” of the\n",
    "image, and is referred to as a **channel**.\n",
    "\n",
    "When applying a convolution to an image in computer vision, it is common to apply a different set of filters to each channel, and then combine the three resulting vectors into a single vector. Taking the different-views-of-the-data metaphor, we can have multiple channels in text processing as well. For example, one channel will be the sequence of words, while another channel is the sequence of corresponding POS tags.\n",
    "\n",
    "Applying the convolution over the words will result in $m$ vectors $p_{1:m}^w$, and applying it over the POS-tags will result in $m$ vectors $p_{1:m}^t$. These two views can then be combined either by summation $p_i = p_i^w + p_i^t$ or by concatenation $p_i = [p_i^w; p_i^t]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to computer vision, we are not forced to shift each convolutional window by only one word forward at each step. We can define a **stride** of 2, 3, etc. words. so that our filters overlap less or skip certain gaps if we have prior knowledge of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"cnn-strided.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a **dilated convolution architecture** [[Yu & Koltun, 2016](https://arxiv.org/pdf/1511.07122.pdf)] the hierarchy of convolution layers each has a stride size of $k - 1$. This allows an exponential growth in the effective window size as a function of the number of layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"cnn-dilated.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References and Further Reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Yoav Goldberg - Neural Network Models for NLP [Morgan & Claypool, 2017]](https://www.morganclaypool.com/doi/abs/10.2200/S00762ED1V01Y201703HLT037).\n",
    "2. [Explosion.ai - Embed, encode, attend, predict: The new deep learning formula for state-of-the-art NLP models](https://explosion.ai/blog/deep-learning-formula-nlp).\n",
    "3. [WildML - Understanding Convolutional Neural Networks for NLP](http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Usupervised learning\n",
    "\n",
    "© Anatolii Stehnii, 2018\n",
    "\n",
    "## Lecture 1: Latent Semantic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: LC_ALL=en_US.UTF-8\n",
      "env: LANG=en_US.UTF-8\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/anatolii.stehnii/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%env LC_ALL=en_US.UTF-8\n",
    "%env LANG=en_US.UTF-8\n",
    "\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunss.otf');\n",
       "    }\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        font-weight: bold;\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunsx.otf');\n",
       "    }\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        font-style: oblique;\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunsi.otf');\n",
       "    }\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        font-weight: bold;\n",
       "        font-style: oblique;\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunso.otf');\n",
       "    }\n",
       "    div.cell{\n",
       "        width:800px;\n",
       "        margin-left:16% !important;\n",
       "        margin-right:auto;\n",
       "    }\n",
       "    h1 {\n",
       "        font-family: Helvetica, serif;\n",
       "    }\n",
       "    h4{\n",
       "        margin-top:12px;\n",
       "        margin-bottom: 3px;\n",
       "       }\n",
       "    div.text_cell_render{\n",
       "        font-family: Computer Modern, \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;\n",
       "        line-height: 145%;\n",
       "        font-size: 130%;\n",
       "        width:800px;\n",
       "        margin-left:auto;\n",
       "        margin-right:auto;\n",
       "    }\n",
       "    .CodeMirror{\n",
       "            font-family: \"Source Code Pro\", source-code-pro,Consolas, monospace;\n",
       "    }\n",
       "    .prompt{\n",
       "        display: None;\n",
       "    }\n",
       "\n",
       "    .text_cell_render h4 {\n",
       "        text-decoration: ;\n",
       "    }\n",
       "\n",
       "    .text_cell_render h5 {\n",
       "        font-weight: 300;\n",
       "        font-size: 22pt;\n",
       "        color: #4057A1;\n",
       "        font-style: italic;\n",
       "        margin-bottom: .5em;\n",
       "        margin-top: 0.5em;\n",
       "        display: block;\n",
       "    }\n",
       "    \n",
       "    .warning {\n",
       "        color: rgb( 240, 20, 20 )\n",
       "    }\n",
       "\n",
       "    div.warn {\n",
       "        background-color: #fcf2f2;\n",
       "        border-color: #dFb5b4;\n",
       "        border-left: 5px solid #dfb5b4;\n",
       "        padding: 0.5em;\n",
       "    }\n",
       "</style>\n",
       "<script>\n",
       "    MathJax.Hub.Config({\n",
       "                        TeX: {\n",
       "                           extensions: [\"AMSmath.js\"]\n",
       "                           },\n",
       "                tex2jax: {\n",
       "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
       "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
       "                },\n",
       "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
       "                \"HTML-CSS\": {\n",
       "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
       "                }\n",
       "        });\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "def css_styling():\n",
    "    styles = open(\"../custom.css\", \"r\").read()\n",
    "    return HTML(styles)\n",
    "css_styling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "MathJax.Hub.Queue(\n",
       "  [\"resetEquationNumbers\", MathJax.InputJax.TeX],\n",
       "  [\"PreProcess\", MathJax.Hub],\n",
       "  [\"Reprocess\", MathJax.Hub]\n",
       ");"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "MathJax.Hub.Queue(\n",
    "  [\"resetEquationNumbers\", MathJax.InputJax.TeX],\n",
    "  [\"PreProcess\", MathJax.Hub],\n",
    "  [\"Reprocess\", MathJax.Hub]\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "Numerical data naturally have a meaning for computational machine. Numbers can be **compared**, a **distance** between vectors can be measured. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5156862774427124"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import spatial\n",
    "a = [1, 5, 6]\n",
    "b = [-2, -6, 1]\n",
    "distance = spatial.distance.cosine(a, b)\n",
    "distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But this can not be done for **words**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = ['weather', 'is', 'good']\n",
    "b = ['sun', 'is', 'shining']\n",
    "distance = None # ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Words are **discrete symbols** which can be encoded as **one-hot-vectors**, sentences can be encoded as **bags of words**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW vector for `weather is good`: [1 1 1 0 0]\n",
      "BoW vector for `sun is shining`: [0 1 0 1 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.66666666666666663"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = {\n",
    "    'weather': [1, 0, 0, 0, 0],\n",
    "    'is': [0, 1, 0, 0, 0],\n",
    "    'good': [0, 0, 1, 0, 0],\n",
    "    'sun': [0, 0, 0, 1, 0],\n",
    "    'shining': [0, 0, 0, 0, 1],\n",
    "}\n",
    "a = np.sum(list(map(lambda w: vectors[w], ['weather', 'is', 'good'])), axis=0)\n",
    "print('BoW vector for `weather is good`: {}'.format(a))\n",
    "b = np.sum(list(map(lambda w: vectors[w], ['sun', 'is', 'shining'])), axis=0)\n",
    "print('BoW vector for `sun is shining`: {}'.format(b))\n",
    "\n",
    "distance = spatial.distance.cosine(a, b)\n",
    "distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But for the whole vocabulary, we will have 500,000-dimensional vectors. Also, this approach totally ignores words **meanings, relations, and similarity**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text meaning\n",
    "Definition of **meaning**:\n",
    " 1. the logical connotation of a word or phrase;\n",
    " 2. what is intended to be, or actually is, expressed or indicated; signification;\n",
    " 3. the thing that is conveyed especially by language.\n",
    " \n",
    "Representation of meaning for a **natural language** is a complex problem. The same words can have a different meaning in different contexts (**polysemy**). Different words also can have a similar meaning (**synonymy**). Words with broader meaning can include meaning for more specific categories (**hypernymy and hyponymy**).\n",
    "\n",
    "### WordNet\n",
    "\n",
    "The simple solution for meaning representation is to manually mark up a graph of relations between words (**WordNet**).\n",
    "\n",
    "![Part of WordNet graph](wordnet-fig1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "def synset_to_str(synset):\n",
    "    return '({}) {}'.format(synset.pos(), ', '.join(map(str, synset.lemma_names())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(n) evil, immorality, wickedness, iniquity\n",
      "(n) evil\n",
      "(n) evil, evilness\n",
      "(a) evil\n",
      "(s) evil, vicious\n",
      "(s) malefic, malevolent, malign, evil\n"
     ]
    }
   ],
   "source": [
    "# synonyms\n",
    "for synset in wn.synsets('evil'):\n",
    "    print(synset_to_str(synset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(n) feline, felid\n",
      "(n) carnivore\n",
      "(n) placental, placental_mammal, eutherian, eutherian_mammal\n",
      "(n) mammal, mammalian\n",
      "(n) vertebrate, craniate\n",
      "(n) chordate\n",
      "(n) animal, animate_being, beast, brute, creature, fauna\n",
      "(n) organism, being\n",
      "(n) living_thing, animate_thing\n",
      "(n) whole, unit\n",
      "(n) object, physical_object\n",
      "(n) physical_entity\n",
      "(n) entity\n"
     ]
    }
   ],
   "source": [
    "# hypernyms\n",
    "hypernyms = lambda s: s.hypernyms()\n",
    "cat = wn.synset('cat.n.01')\n",
    "for synset in list(cat.closure(hypernyms)):\n",
    "    print(synset_to_str(synset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(n) domestic_cat, house_cat, Felis_domesticus, Felis_catus\n",
      "(n) wildcat\n",
      "(n) Abyssinian, Abyssinian_cat\n",
      "(n) alley_cat\n",
      "(n) Angora, Angora_cat\n",
      "(n) Burmese_cat\n",
      "(n) Egyptian_cat\n",
      "(n) kitty, kitty-cat, puss, pussy, pussycat\n",
      "(n) Maltese, Maltese_cat\n",
      "(n) Manx, Manx_cat\n",
      "(n) mouser\n",
      "(n) Persian_cat\n",
      "(n) Siamese_cat, Siamese\n",
      "(n) tabby, tabby_cat\n",
      "(n) tabby, queen\n",
      "(n) tiger_cat\n",
      "(n) tom, tomcat\n",
      "(n) tortoiseshell, tortoiseshell-cat, calico_cat\n",
      "(n) cougar, puma, catamount, mountain_lion, painter, panther, Felis_concolor\n",
      "(n) European_wildcat, catamountain, Felis_silvestris\n",
      "(n) jaguarundi, jaguarundi_cat, jaguarondi, eyra, Felis_yagouaroundi\n",
      "(n) jungle_cat, Felis_chaus\n",
      "(n) kaffir_cat, caffer_cat, Felis_ocreata\n",
      "(n) leopard_cat, Felis_bengalensis\n",
      "(n) lynx, catamount\n",
      "(n) manul, Pallas's_cat, Felis_manul\n",
      "(n) margay, margay_cat, Felis_wiedi\n",
      "(n) ocelot, panther_cat, Felis_pardalis\n",
      "(n) sand_cat\n",
      "(n) serval, Felis_serval\n",
      "(n) tiger_cat, Felis_tigrina\n",
      "(n) blue_point_Siamese\n",
      "(n) gib\n",
      "(n) bobcat, bay_lynx, Lynx_rufus\n",
      "(n) Canada_lynx, Lynx_canadensis\n",
      "(n) caracal, desert_lynx, Lynx_caracal\n",
      "(n) common_lynx, Lynx_lynx\n",
      "(n) spotted_lynx, Lynx_pardina\n"
     ]
    }
   ],
   "source": [
    "hyponyms = lambda s: s.hyponyms()\n",
    "for synset in list(cat.closure(hyponyms)):\n",
    "    print(synset_to_str(synset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# distance - shortest path in hyponyms/hypernims graph between two words\n",
    "dog = wn.synset('dog.n.01')\n",
    "dog.shortest_path_distance(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cow = wn.synset('cow.n.01')\n",
    "cat.shortest_path_distance(cow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human = wn.synset('human.n.01')\n",
    "cat.shortest_path_distance(human)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other WordNet features: http://www.nltk.org/howto/wordnet.html\n",
    "\n",
    "WordNet is interesting as a word catalog, but it has some **major issues**:\n",
    "1. whole **language complexity** cannot be inferred only from synonymy, hyponymy, and hypernymy relations;\n",
    "2. WordNet is missing new words, it requires **manual labor** to adapt, and it is prone to **human errors**;\n",
    "3. word similarity is **not accurate**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A possible solution is to map words into $n$-dimensional space, where relations between words will be encoded into **spatial words positions**.\n",
    "\n",
    "### LSA core idea\n",
    "\n",
    "A word’s meaning is given by the words that frequently appear close-by.\n",
    "\n",
    "*\"You shall know a word by the company it keeps\" (John Rupert Firth. 1957:11)*\n",
    "\n",
    "**Distributional hypothesis**: linguistic items with similar distributions have similar meanings. https://en.wikipedia.org/wiki/Distributional_semantics\n",
    "\n",
    "To find a representation of a word $w$ we need to use it's **context**: a set of words, which occurred nearby is some window (for example, paragraph).\n",
    "\n",
    "### LSA algorithm\n",
    "\n",
    "1. Form a term-document matrix (TF-IDF, BoW) to describe a words context; it is a sparse matrix $\\textbf{X}$ where terms are rows and documents are columns:\n",
    "\n",
    "    \\begin{equation}\n",
    "    \\begin{matrix} \n",
    "     & \\textbf{d}_j \\\\\n",
    "     & \\downarrow \\\\\n",
    "    \\textbf{t}_i^T \\rightarrow &\n",
    "    \\begin{bmatrix} \n",
    "    x_{1,1} & \\dots & x_{1,j} & \\dots & x_{1,n} \\\\\n",
    "    \\vdots & \\ddots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    x_{i,1} & \\dots & x_{i,j} &  \\dots & x_{i,n} \\\\\n",
    "    \\vdots & \\ddots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    x_{m,1} & \\dots & x_{m,j} & \\dots & x_{m,n} \\\\\n",
    "    \\end{bmatrix}\n",
    "    \\end{matrix}\n",
    "    \\end{equation}\n",
    "\n",
    "2. Apply **rank lowering method** (SVD) to it to reduce dimensionality and extract main components for terms (or for documents, if your task is to find vector representations for documents):\n",
    "\n",
    "    \\begin{equation}\n",
    "    \\textbf{X} = \\textbf{U} \\textbf{S} \\textbf{V}^T\n",
    "    \\end{equation}\n",
    "\n",
    "    \\begin{equation}\n",
    "    \\begin{matrix} \n",
    "     & X & & & U & & \\textbf{S} & & V^T \\\\\n",
    "     & (\\textbf{d}_j) & & & & & & & (\\hat{\\textbf{d}}_j) \\\\\n",
    "     & \\downarrow & & & & & & & \\downarrow \\\\\n",
    "    (\\textbf{t}_i^T) \\rightarrow \n",
    "    &\n",
    "    \\begin{bmatrix}\n",
    "    x_{1,1} & \\dots & x_{1,j} & \\dots & x_{1,n} \\\\\n",
    "    \\vdots & \\ddots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    x_{i,1} & \\dots & x_{i,j} &  \\dots & x_{i,n} \\\\\n",
    "    \\vdots & \\ddots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    x_{m,1} & \\dots & x_{m,j} & \\dots & x_{m,n} \\\\\n",
    "    \\end{bmatrix}\n",
    "    &\n",
    "    =\n",
    "    &\n",
    "    (\\hat{\\textbf{t}}_i^T) \\rightarrow\n",
    "    &\n",
    "    \\begin{bmatrix} \n",
    "    \\begin{bmatrix} \\, \\\\ \\, \\\\ \\textbf{u}_1 \\\\ \\, \\\\ \\,\\end{bmatrix} \n",
    "    \\dots\n",
    "    \\begin{bmatrix} \\, \\\\ \\, \\\\ \\textbf{u}_l \\\\ \\, \\\\ \\, \\end{bmatrix}\n",
    "    \\end{bmatrix}\n",
    "    &\n",
    "    \\cdot\n",
    "    &\n",
    "    \\begin{bmatrix} \n",
    "    s_1 & \\dots & 0 \\\\\n",
    "    \\vdots & \\ddots & \\vdots \\\\\n",
    "    0 & \\dots & s_l \\\\\n",
    "    \\end{bmatrix}\n",
    "    &\n",
    "    \\cdot\n",
    "    &\n",
    "    \\begin{bmatrix} \n",
    "    \\begin{bmatrix} & & \\textbf{v}_1 & & \\end{bmatrix} \\\\\n",
    "    \\vdots \\\\\n",
    "    \\begin{bmatrix} & & \\textbf{v}_l & & \\end{bmatrix}\n",
    "    \\end{bmatrix}\n",
    "    \\end{matrix}\n",
    "    \\end{equation}\n",
    "\n",
    "3. Columns of $\\textbf{U}$ are linear independent factors of word vectors; singular values $\\textbf{s}_n$ can be used to order these factors from more influential to less influential. Select first $\\textbf{l}$ components to obtain $\\textbf{l}$-dimensional dense representation for each word-vector. \n",
    "\n",
    "4. Calculate part of variance explained by your representation:\n",
    "\n",
    "    \\begin{equation}\n",
    "    R^2 = \\frac{\\sum_{i=0}^{l} \\textbf{s}_i^2}{\\sum_{j=0}^{n} \\textbf{s}_j^2}\n",
    "    \\end{equation}\n",
    "\n",
    "5. PROFIT!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. SVD is simple and fast.\n",
    "2. This method also can be used to find embeddings not only for words, but also for documents, movies, songs, etc (Collaborative filtering, Entity Embeddings)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cons\n",
    "1. SVD is a linear transformation; therefore, it can not capture non-linear relations between words. \n",
    "2. Not so efficient as state-of-the-art methods (neural networks for example)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

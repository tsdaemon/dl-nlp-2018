{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSA\n",
    "\n",
    "© Anatolii Stehnii, 2018\n",
    "\n",
    "Main goal of this assignment is to give you a basic understanding of how Latent Semantic Analysis is performed and how to interpret it results. In this work you will calculate word embeddings using LSA for arbitrary text and explore their properties.\n",
    "\n",
    "Code from [Yuri Guts's Thrones2Vec](https://github.com/YuriyGuts/thrones2vec/blob/master/Thrones2Vec.ipynb) is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: LC_ALL=en_US.UTF-8\n",
      "env: LANG=en_US.UTF-8\n"
     ]
    }
   ],
   "source": [
    "%env LC_ALL=en_US.UTF-8\n",
    "%env LANG=en_US.UTF-8\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [10, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpus preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, download any text and save it in `./data/part1/corpus.txt`. I recommend you to use English text, but if you feel brave enough, you can setup a pipleline for any other language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus is 9748084 characters long.\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"../data/part1\"\n",
    "corpus_file = os.path.join(data_dir, \"corpus.txt\")\n",
    "\n",
    "with open(corpus_file, \"r\", ) as f:\n",
    "    corpus = f.read()\n",
    "print(\"Corpus is {0} characters long.\".format(len(corpus)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to split our corpus on documents and split documents on terms. Use English tokenizers from NLTK or create your own function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/anatolii.stehnii/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"punkt\")\n",
    "nltk_english = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "# use this or define your own document_tokenize\n",
    "document_tokenize = lambda corpus: nltk_english.tokenize(corpus)\n",
    "\n",
    "# use this or define your own word_tokenize\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split corpus on documents\n",
    "documents_raw = document_tokenize(corpus)\n",
    "# split documents on tokens\n",
    "documents = list(map(word_tokenize, documents_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['``', 'The', 'wildlings', 'are', 'dead', '.', \"''\"]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add your preprocessing if needed or use default:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "\n",
    "# default preprocessing – leave only alphabetical characters and stem tokens\n",
    "# redefine this function, if you need another pipeline\n",
    "def preprocess(word):\n",
    "    stem = ps.stem(word)\n",
    "    clean = re.sub(\"[^a-zA-Z]\",\"\", stem)\n",
    "    clean_lower = clean.lower()\n",
    "    return clean_lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/anatolii.stehnii/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# replace each word with preprocessed\n",
    "documents = [[preprocess(word) for word in document if word.lower() not in stop_words] for document in documents]\n",
    "# filter empty tokens\n",
    "documents = [[word for word in document if word] for document in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw document: He was an old man, past fifty, and he had seen the lordlings come and go.\n",
      "\n",
      "Preprocessed document: ['old', 'man', 'past', 'fifti', 'seen', 'lordl', 'come', 'go']\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "The corpus contains 912,299 tokens in 158,726 documents\n"
     ]
    }
   ],
   "source": [
    "# Compare raw and preprocessed documents\n",
    "print(\"Raw document: {}\\n\".format(documents_raw[5]))\n",
    "print(\"Preprocessed document: {}\\n\".format(documents[5]))\n",
    "print(\"-\"*80)\n",
    "token_count = sum([len(document) for document in documents])\n",
    "print(\"The corpus contains {0:,} tokens in {1:,} documents\".format(token_count, len(documents)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are filtering rare words from our documents. We clearly will not be able to analyze a word, if it occurs only a few times in a text. Define your threshold for a minimum word occurence in the text to filter rare words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The corpus vocabulary contains 9,978 unique words, 0 with less than 3 occurences.\n"
     ]
    }
   ],
   "source": [
    "min_word_count = 3\n",
    "\n",
    "words_count = {}\n",
    "for d in documents:\n",
    "    for w in d:\n",
    "        if w in words_count:\n",
    "            words_count[w] += 1\n",
    "        else:\n",
    "            words_count[w] = 1\n",
    "\n",
    "rare_words = {w for w, count in words_count.items() if count < min_word_count}\n",
    "print(\"The corpus vocabulary contains {0:,} unique words, {1:,} with less than {2:} occurences.\".format(len(words_count), len(rare_words), min_word_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define your own set of stop words or use default from NLTK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/anatolii.stehnii/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "#stop_words = {'a', 'an', 'the'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered document: ['old', 'man', 'past', 'fifti', 'seen', 'lordl', 'come', 'go']\n",
      "--------------------------------------------------------------------------------\n",
      "A filtered vocabulary contains 9977 unique words\n"
     ]
    }
   ],
   "source": [
    "# remove stop words and rare words from documents\n",
    "remove_words = rare_words | stop_words\n",
    "documents = [[word for word in document if word not in remove_words] for document in documents]\n",
    "print(\"Filtered document: {}\" .format(documents[5]))\n",
    "print(\"-\"*80)\n",
    "\n",
    "all_words = {word for document in documents for word in document}\n",
    "vocabulary = {w:i for i, w in enumerate(sorted(all_words))}\n",
    "print(\"A filtered vocabulary contains {} unique words\".format(len(vocabulary)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term-document matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you need to transform your corpus into term-document matrix of any type you want (BoW, TF-IDF). Use a sparse matrix, if you have large amount of data. Don't forget to save your vocabulary so you can restore a row index for each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(vocabulary=all_words)\n",
    "tfidf_docs = [' '.join(d) for d in documents]\n",
    "tf_idf_matrix = tfidf.fit_transform(tfidf_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<158726x9977 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 891779 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD\n",
    "\n",
    "Perform SVD of term-document matrix and reduce it's dimensionality to n_dim components. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_dim = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd = TruncatedSVD(n_dim)\n",
    "u = svd.fit_transform(tf_idf_matrix.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_embeddings = u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select a set of words you would like to explore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = ['king', 'queen', 'robert', 'cersei', 'daeneri', 'man', 'woman']\n",
    "indexes = [vocabulary[word] for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl8AAAJCCAYAAAD+96JYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nA+Qh+aeNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a2169e780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "word_vectors = [(word_embeddings[i, 0], word_embeddings[i, 1]) for i in indexes]\n",
    "xy = list(zip(*word_vectors))\n",
    "x=xy[0]\n",
    "y=xy[1]\n",
    "plt.plot(x, y, '*')\n",
    "\n",
    "for word, x, y in zip (words, x, y):\n",
    "    plt.text(x, y, word)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a plot with your words, use first two components for x and y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word analogy\n",
    "1. Measure distances (cosine, euclidean) between test words.\n",
    "2. Check if distances have meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity for words king and queen: 0.38262248782339203\n",
      "Similarity for words king and robert: 0.20129086518351225\n",
      "Similarity for words king and cersei: 0.7478332236321272\n",
      "Similarity for words king and daeneri: 0.8348700272712637\n",
      "Similarity for words king and man: 1.0328579398014928\n",
      "Similarity for words king and woman: 0.849243885816946\n",
      "Similarity for words queen and robert: 0.1990035184797786\n",
      "Similarity for words queen and cersei: 0.3361404197540756\n",
      "Similarity for words queen and daeneri: 0.2445403115619068\n",
      "Similarity for words queen and man: 0.6584062248668459\n",
      "Similarity for words queen and woman: 0.36560465026464073\n",
      "Similarity for words robert and cersei: 0.3739849676795839\n",
      "Similarity for words robert and daeneri: 0.4309901468262006\n",
      "Similarity for words robert and man: 0.9256020534333234\n",
      "Similarity for words robert and woman: 0.5142930491432093\n",
      "Similarity for words cersei and daeneri: 0.16393277399042683\n",
      "Similarity for words cersei and man: 0.9358999437693635\n",
      "Similarity for words cersei and woman: 0.31162580603842915\n",
      "Similarity for words daeneri and man: 0.7776438516989267\n",
      "Similarity for words daeneri and woman: 0.2997908168257212\n",
      "Similarity for words man and woman: 0.3262001481335963\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "from scipy.spatial.distance import cosine, euclidean\n",
    "\n",
    "for w1, w2 in itertools.combinations(words, 2):\n",
    "    v1 = word_embeddings[vocabulary[w1]]\n",
    "    v2 = word_embeddings[vocabulary[w2]]\n",
    "    distance = cosine(v1, v2)\n",
    "    print('Similarity for words {} and {}: {}'.format(w1, w2, distance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Components meaning\n",
    "\n",
    "Try to find meaning for individual components: select words with the most high values and the most low values for some dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('would', -7.533187053126823),\n",
       " ('know', -6.886688499259003),\n",
       " ('lord', -4.728021270568082),\n",
       " ('one', -4.564660283657913),\n",
       " ('could', -2.677117708172796),\n",
       " ('nt', -2.514082559526418),\n",
       " ('want', -2.2699717132060635),\n",
       " ('say', -1.9102692123559524),\n",
       " ('see', -1.8545201668093596),\n",
       " ('like', -1.7676718814295944),\n",
       " ('king', -1.5739949840394905),\n",
       " ('come', -1.5578939658533857),\n",
       " ('look', -1.5423676438908254),\n",
       " ('well', -1.4567513084253623),\n",
       " ('never', -1.3147301524310295),\n",
       " ('hand', -1.3087175147022414),\n",
       " ('men', -1.237275654788786),\n",
       " ('told', -1.2264982024571345),\n",
       " ('even', -1.1686564779673148),\n",
       " ('back', -1.1483799349946873),\n",
       " ('thought', -1.1465955067684148),\n",
       " ('ask', -1.1063004572618258),\n",
       " ('man', -1.080043062269019),\n",
       " ('go', -1.0649178728311939),\n",
       " ('father', -0.932498538413195),\n",
       " ('eye', -0.9184140837580944),\n",
       " ('take', -0.9019151446091814),\n",
       " ('us', -0.8945940893264667),\n",
       " ('time', -0.8702544054598159),\n",
       " ('son', -0.8073788060378302),\n",
       " ('day', -0.786350729826035),\n",
       " ('way', -0.7839541754850766),\n",
       " ('need', -0.7609325245294859),\n",
       " ('make', -0.7566121531659956),\n",
       " ('face', -0.7215726450732167),\n",
       " ('die', -0.7062228448788184),\n",
       " ('kill', -0.6874647600970514),\n",
       " ('think', -0.6869698976593129),\n",
       " ('long', -0.6861622759530884),\n",
       " ('brother', -0.6861042631785437),\n",
       " ('command', -0.673106387985992),\n",
       " ('knew', -0.6559514145999991),\n",
       " ('still', -0.6370682531748676),\n",
       " ('though', -0.6363780429822626),\n",
       " ('might', -0.6284870694444428),\n",
       " ('made', -0.6200378982447882),\n",
       " ('hi', -0.615172849883633),\n",
       " ('wall', -0.5984947580921043),\n",
       " ('whi', -0.5897669557910376),\n",
       " ('call', -0.5889584073734868)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "component = 1\n",
    "values = word_embeddings[:,component].tolist()\n",
    "\n",
    "word_values = list(sorted(zip(vocabulary.keys(), values), key=lambda x: x[1]))\n",
    "word_values[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ygritt', 0.05026513092902153),\n",
       " ('bronn', 0.05514521923716343),\n",
       " ('sorri', 0.05577623875547464),\n",
       " ('uncertainli', 0.05697112996984601),\n",
       " ('arstan', 0.0576178274899608),\n",
       " ('sadli', 0.05908560680459496),\n",
       " ('podrick', 0.06023875748571065),\n",
       " ('tormund', 0.06220058950603515),\n",
       " ('shock', 0.0634293274188511),\n",
       " ('tom', 0.06379589938748746),\n",
       " ('oh', 0.06484204271663835),\n",
       " ('tone', 0.06682320558307783),\n",
       " ('loudli', 0.06694442004113364),\n",
       " ('angrili', 0.06698887730115809),\n",
       " ('gerri', 0.06989208619671157),\n",
       " ('bluntli', 0.07240590659027135),\n",
       " ('khaleesi', 0.0795237899752583),\n",
       " ('pyp', 0.07968689976851136),\n",
       " ('scorn', 0.08129975750611045),\n",
       " ('barristan', 0.08252685734205803),\n",
       " ('lem', 0.08549839274009191),\n",
       " ('quietli', 0.09240388823637476),\n",
       " ('luwin', 0.0927418500524789),\n",
       " ('haldon', 0.09337491309048697),\n",
       " ('vari', 0.09800510450071473),\n",
       " ('maester', 0.10122690318484907),\n",
       " ('stubbornli', 0.10340720263448336),\n",
       " ('grenn', 0.10677166595484901),\n",
       " ('brienn', 0.11028996700840257),\n",
       " ('robb', 0.1359015929539227),\n",
       " ('sam', 0.1392483561185341),\n",
       " ('davo', 0.1439448756856868),\n",
       " ('jorah', 0.14487780536537195),\n",
       " ('jojen', 0.1463138905608694),\n",
       " ('word', 0.1468133566996205),\n",
       " ('meera', 0.15437233588306284),\n",
       " ('softli', 0.15517264369310305),\n",
       " ('aye', 0.16546488745470317),\n",
       " ('sharpli', 0.17925218122131492),\n",
       " ('catelyn', 0.20785648470596294),\n",
       " ('jon', 0.24471573357559853),\n",
       " ('ned', 0.24599390395131818),\n",
       " ('hodor', 0.26436616064683394),\n",
       " ('ser', 0.2705952427583624),\n",
       " ('bran', 0.2886161413635267),\n",
       " ('voic', 0.3040319944072321),\n",
       " ('dani', 0.35931789293345456),\n",
       " ('ye', 0.6046295216478503),\n",
       " ('tyrion', 0.6894297718385408),\n",
       " ('said', 22.714477818644458)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_values[-50:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Save results\n",
    "We will need preprocessed dataset and word embeddings in the next assignment, so let's save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store vocabulary as word per line. Indexes can be easily restored from order, therore they are ommited\n",
    "with open(os.path.join(data_dir, 'vocabulary.txt'), \"w\") as f:\n",
    "    vocab_str = '\\n'.join(vocabulary.keys())\n",
    "    f.write(vocab_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store corpus, document per line, each token replaced with index\n",
    "with open(os.path.join(data_dir, 'corpus_preprocessed.txt'), \"w\") as f:\n",
    "    corpus_str = '\\n'.join([' '.join([str(vocabulary[token]) for token in document]) for document in documents])\n",
    "    f.write(corpus_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store LSA embeddings\n",
    "np.save(os.path.join(data_dir, 'lsa_embeddings.npy'), word_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

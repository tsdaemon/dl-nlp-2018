{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2vec\n",
    "\n",
    "In this work you will calculate word embeddings with neural model and compare its results with LSA.\n",
    "\n",
    "Code from [Mateusz Bednarski](https://towardsdatascience.com/implementing-word2vec-in-pytorch-skip-gram-model-e6bae040d2fb) article is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: LC_ALL=en_US.UTF-8\n",
      "env: LANG=en_US.UTF-8\n"
     ]
    }
   ],
   "source": [
    "%env LC_ALL=en_US.UTF-8\n",
    "%env LANG=en_US.UTF-8\n",
    "\n",
    "import nltk\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [10, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "corpus = [\n",
    "    'he is a king',\n",
    "    'she is a queen',\n",
    "    'he is a man',\n",
    "    'she is a woman',\n",
    "    'warsaw is poland capital',\n",
    "    'berlin is germany capital',\n",
    "    'paris is france capital',\n",
    "]\n",
    "tokenized_corpus = list(map(word_tokenize, corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocabulary = []\n",
    "for sentence in tokenized_corpus:\n",
    "    for token in sentence:\n",
    "        if token not in vocabulary:\n",
    "            vocabulary.append(token)\n",
    "\n",
    "word2idx = {w: idx for (idx, w) in enumerate(vocabulary)}\n",
    "idx2word = {idx: w for (idx, w) in enumerate(vocabulary)}\n",
    "\n",
    "vocabulary_size = len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "window_size = 2\n",
    "idx_pairs = []\n",
    "# for each sentence\n",
    "for sentence in tokenized_corpus:\n",
    "    indices = [word2idx[word] for word in sentence]\n",
    "    # for each word, threated as center word\n",
    "    for center_word_pos in range(len(indices)):\n",
    "        # for each window position\n",
    "        for w in range(-window_size, window_size + 1):\n",
    "            context_word_pos = center_word_pos + w\n",
    "            # make soure not jump out sentence\n",
    "            if context_word_pos < 0 or context_word_pos >= len(indices) or center_word_pos == context_word_pos:\n",
    "                continue\n",
    "            context_word_idx = indices[context_word_pos]\n",
    "            idx_pairs.append((indices[center_word_pos], context_word_idx))\n",
    "\n",
    "idx_pairs = np.array(idx_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_input_layer(word_idx):\n",
    "    x = torch.zeros(vocabulary_size).float()\n",
    "    x[word_idx] = 1.0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anatolii.stehnii/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epo 0: 3.5163509845733643\n",
      "Loss at epo 10: 3.366441011428833\n",
      "Loss at epo 20: 3.2494847774505615\n",
      "Loss at epo 30: 3.155801773071289\n",
      "Loss at epo 40: 3.0792462825775146\n",
      "Loss at epo 50: 3.0156049728393555\n",
      "Loss at epo 60: 2.9618518352508545\n",
      "Loss at epo 70: 2.915764808654785\n",
      "Loss at epo 80: 2.8756775856018066\n",
      "Loss at epo 90: 2.8403329849243164\n",
      "Loss at epo 100: 2.808767080307007\n",
      "Loss at epo 110: 2.780237913131714\n",
      "Loss at epo 120: 2.7541699409484863\n",
      "Loss at epo 130: 2.730113983154297\n",
      "Loss at epo 140: 2.7077176570892334\n",
      "Loss at epo 150: 2.686706066131592\n",
      "Loss at epo 160: 2.666868209838867\n",
      "Loss at epo 170: 2.6480331420898438\n",
      "Loss at epo 180: 2.6300718784332275\n",
      "Loss at epo 190: 2.612882137298584\n",
      "Loss at epo 200: 2.5963799953460693\n",
      "Loss at epo 210: 2.5804965496063232\n",
      "Loss at epo 220: 2.565176486968994\n",
      "Loss at epo 230: 2.550365447998047\n",
      "Loss at epo 240: 2.5360186100006104\n",
      "Loss at epo 250: 2.522095203399658\n",
      "Loss at epo 260: 2.5085573196411133\n",
      "Loss at epo 270: 2.495373487472534\n",
      "Loss at epo 280: 2.4825172424316406\n",
      "Loss at epo 290: 2.4699647426605225\n",
      "Loss at epo 300: 2.4576973915100098\n",
      "Loss at epo 310: 2.4456989765167236\n",
      "Loss at epo 320: 2.4339590072631836\n",
      "Loss at epo 330: 2.422466516494751\n",
      "Loss at epo 340: 2.4112164974212646\n",
      "Loss at epo 350: 2.4002015590667725\n",
      "Loss at epo 360: 2.3894171714782715\n",
      "Loss at epo 370: 2.378859281539917\n",
      "Loss at epo 380: 2.368525743484497\n",
      "Loss at epo 390: 2.3584117889404297\n",
      "Loss at epo 400: 2.3485140800476074\n",
      "Loss at epo 410: 2.338831663131714\n",
      "Loss at epo 420: 2.3293607234954834\n",
      "Loss at epo 430: 2.320098876953125\n",
      "Loss at epo 440: 2.311044454574585\n",
      "Loss at epo 450: 2.302194356918335\n",
      "Loss at epo 460: 2.2935469150543213\n",
      "Loss at epo 470: 2.2850992679595947\n",
      "Loss at epo 480: 2.276850700378418\n",
      "Loss at epo 490: 2.268798828125\n",
      "Loss at epo 500: 2.260941743850708\n",
      "Loss at epo 510: 2.253279209136963\n",
      "Loss at epo 520: 2.245807647705078\n",
      "Loss at epo 530: 2.2385263442993164\n",
      "Loss at epo 540: 2.231433629989624\n",
      "Loss at epo 550: 2.224527359008789\n",
      "Loss at epo 560: 2.217805862426758\n",
      "Loss at epo 570: 2.2112674713134766\n",
      "Loss at epo 580: 2.204909086227417\n",
      "Loss at epo 590: 2.198728561401367\n",
      "Loss at epo 600: 2.1927223205566406\n",
      "Loss at epo 610: 2.1868884563446045\n",
      "Loss at epo 620: 2.1812233924865723\n",
      "Loss at epo 630: 2.1757240295410156\n",
      "Loss at epo 640: 2.17038631439209\n",
      "Loss at epo 650: 2.165205240249634\n",
      "Loss at epo 660: 2.1601784229278564\n",
      "Loss at epo 670: 2.1552999019622803\n",
      "Loss at epo 680: 2.150566816329956\n",
      "Loss at epo 690: 2.1459736824035645\n",
      "Loss at epo 700: 2.1415164470672607\n",
      "Loss at epo 710: 2.1371893882751465\n",
      "Loss at epo 720: 2.132988929748535\n",
      "Loss at epo 730: 2.1289100646972656\n",
      "Loss at epo 740: 2.1249477863311768\n",
      "Loss at epo 750: 2.121098041534424\n",
      "Loss at epo 760: 2.117356300354004\n",
      "Loss at epo 770: 2.113717555999756\n",
      "Loss at epo 780: 2.110178232192993\n",
      "Loss at epo 790: 2.106733798980713\n",
      "Loss at epo 800: 2.103381633758545\n",
      "Loss at epo 810: 2.10011625289917\n",
      "Loss at epo 820: 2.096933603286743\n",
      "Loss at epo 830: 2.093832015991211\n",
      "Loss at epo 840: 2.090806484222412\n",
      "Loss at epo 850: 2.0878539085388184\n",
      "Loss at epo 860: 2.084972620010376\n",
      "Loss at epo 870: 2.082158088684082\n",
      "Loss at epo 880: 2.0794081687927246\n",
      "Loss at epo 890: 2.0767197608947754\n",
      "Loss at epo 900: 2.074089527130127\n",
      "Loss at epo 910: 2.071516752243042\n",
      "Loss at epo 920: 2.068997621536255\n",
      "Loss at epo 930: 2.066530704498291\n",
      "Loss at epo 940: 2.0641136169433594\n",
      "Loss at epo 950: 2.06174373626709\n",
      "Loss at epo 960: 2.059420585632324\n",
      "Loss at epo 970: 2.057140588760376\n",
      "Loss at epo 980: 2.054903268814087\n",
      "Loss at epo 990: 2.052706480026245\n"
     ]
    }
   ],
   "source": [
    "embedding_dims = 2\n",
    "W1 = Variable(torch.randn(embedding_dims, vocabulary_size).float(), requires_grad=True)\n",
    "W2 = Variable(torch.randn(vocabulary_size, embedding_dims).float(), requires_grad=True)\n",
    "num_epochs = 1000\n",
    "learning_rate = 0.001\n",
    "\n",
    "for epo in range(num_epochs):\n",
    "    loss_val = 0\n",
    "    for data, target in idx_pairs:\n",
    "        x = Variable(get_input_layer(data)).float()\n",
    "        y_true = Variable(torch.from_numpy(np.array([target])).long())\n",
    "\n",
    "        z1 = torch.matmul(W1, x)\n",
    "        z2 = torch.matmul(W2, z1)\n",
    "    \n",
    "        log_softmax = F.log_softmax(z2, dim=0)\n",
    "\n",
    "        loss = F.nll_loss(log_softmax.view(1,-1), y_true)\n",
    "        loss_val += loss.data[0]\n",
    "        loss.backward()\n",
    "        W1.data -= learning_rate * W1.grad.data\n",
    "        W2.data -= learning_rate * W2.grad.data\n",
    "\n",
    "        W1.grad.data.zero_()\n",
    "        W2.grad.data.zero_()\n",
    "    if epo % 10 == 0:    \n",
    "        print(f'Loss at epo {epo}: {loss_val/len(idx_pairs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_embeddings = (W1.transpose(0, 1)+W2).detach().numpy()/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = ['he', 'she', 'king', 'queen']\n",
    "indexes = [word2idx[word] for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl8AAAJCCAYAAAD+96JYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1da602e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "coordinates  = [word_embeddings[i,0:2] for i in indexes]\n",
    "xdata, ydata = zip(*coordinates)\n",
    "plt.plot(xdata, ydata, '*')\n",
    "for c, word in zip(coordinates, words):\n",
    "    plt.text(c[0], c[1], word)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

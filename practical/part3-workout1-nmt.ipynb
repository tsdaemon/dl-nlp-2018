{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Machine Translation\n",
    "\n",
    "In this work you need to implement any Seq2seq architecture to train neural German-Ukrainian translator.\n",
    "\n",
    "Mostly copy of [practical-pytorch](https://github.com/spro/practical-pytorch/blob/master/seq2seq-translation/seq2seq-translation.ipynb) tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from tokenize_uk import tokenize_words\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Managing **environment** (CPU or GPU) is not simple in pytorch. You need to explicitly select environment for all tensors in your model. Use this constant to define GPU usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "USE_CUDA = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "We will use open source sentence pairs from [tatoeba.org](https://tatoeba.org/eng/downloads). Download [sentences archive](http://downloads.tatoeba.org/exports/sentences.tar.bz2) and extract it into `./data/part3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: DATA_DIR=./../data/part3/\n"
     ]
    }
   ],
   "source": [
    "%env DATA_DIR = ./../data/part3/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-07-07 14:20:50--  https://downloads.tatoeba.org/exports/sentences.tar.bz2\n",
      "Resolving downloads.tatoeba.org (downloads.tatoeba.org)... 94.130.77.194\n",
      "Connecting to downloads.tatoeba.org (downloads.tatoeba.org)|94.130.77.194|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 106890169 (102M) [application/octet-stream]\n",
      "Saving to: ‘./../data/part3/sentences.tar.bz2.1’\n",
      "\n",
      "sentences.tar.bz2.1 100%[===================>] 101.94M  2.20MB/s    in 47s     \n",
      "\n",
      "2018-07-07 14:21:37 (2.19 MB/s) - ‘./../data/part3/sentences.tar.bz2.1’ saved [106890169/106890169]\n",
      "\n",
      "x sentences.csv\n"
     ]
    }
   ],
   "source": [
    "!wget https://downloads.tatoeba.org/exports/sentences.tar.bz2 -P $DATA_DIR\n",
    "!tar xvjC $DATA_DIR -f $DATA_DIR/sentences.tar.bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-07-07 14:21:54--  https://downloads.tatoeba.org/exports/links.tar.bz2\n",
      "Resolving downloads.tatoeba.org (downloads.tatoeba.org)... 94.130.77.194\n",
      "Connecting to downloads.tatoeba.org (downloads.tatoeba.org)|94.130.77.194|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 72991002 (70M) [application/octet-stream]\n",
      "Saving to: ‘./../data/part3/links.tar.bz2.1’\n",
      "\n",
      "links.tar.bz2.1     100%[===================>]  69.61M  2.21MB/s    in 32s     \n",
      "\n",
      "2018-07-07 14:22:26 (2.19 MB/s) - ‘./../data/part3/links.tar.bz2.1’ saved [72991002/72991002]\n",
      "\n",
      "x links.csv\n"
     ]
    }
   ],
   "source": [
    "!wget https://downloads.tatoeba.org/exports/links.tar.bz2 -P $DATA_DIR\n",
    "!tar xvjC $DATA_DIR -f $DATA_DIR/links.tar.bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = './../data/part3/'\n",
    "sentences = pd.read_csv(os.path.join(data_dir, 'sentences.csv'), names=['id', 'lang', 'text'], header=None, delimiter='\\t')\n",
    "links = pd.read_csv(os.path.join(data_dir, 'links.csv'), names=['sent_id', 'tran_id'], header=None, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose any languages you want to train translator for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textukr</th>\n",
       "      <th>textdeu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Він наказав мені негайно вийти з кімнати.</td>\n",
       "      <td>Er befahl mir, den Raum umgehend zu verlassen.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>У всесвіті багато галактик.</td>\n",
       "      <td>Es gibt viele Galaxien im Universum.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>У Всесвіті є багато галактик.</td>\n",
       "      <td>Es gibt viele Galaxien im Universum.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Вона приймає душ щоранку.</td>\n",
       "      <td>Sie nimmt jeden Morgen eine Dusche.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Вона приймає душ щоранку.</td>\n",
       "      <td>Sie duscht jeden Morgen.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     textukr  \\\n",
       "0  Він наказав мені негайно вийти з кімнати.   \n",
       "1                У всесвіті багато галактик.   \n",
       "2              У Всесвіті є багато галактик.   \n",
       "3                  Вона приймає душ щоранку.   \n",
       "4                  Вона приймає душ щоранку.   \n",
       "\n",
       "                                          textdeu  \n",
       "0  Er befahl mir, den Raum umgehend zu verlassen.  \n",
       "1            Es gibt viele Galaxien im Universum.  \n",
       "2            Es gibt viele Galaxien im Universum.  \n",
       "3             Sie nimmt jeden Morgen eine Dusche.  \n",
       "4                        Sie duscht jeden Morgen.  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_lang = 'ukr'\n",
    "target_lang = 'deu'\n",
    "\n",
    "source_sentences = sentences[sentences.lang == source_lang]\n",
    "source_sentences = source_sentences.merge(links, left_on='id', right_on='sent_id')\n",
    "target_sentences = sentences[sentences.lang == target_lang]\n",
    "\n",
    "bilang_sentences = source_sentences.merge(target_sentences, left_on='tran_id', \n",
    "                                          right_on='id', \n",
    "                                          suffixes=[source_lang, target_lang])\n",
    "bilang_sentences = bilang_sentences[['text'+source_lang, 'text'+target_lang]]\n",
    "\n",
    "file_name = os.path.join(data_dir, '{source}-{target}.csv'.format(source=source_lang, target=target_lang)) \n",
    "bilang_sentences.to_csv(file_name, index=False, sep='\\t')\n",
    "\n",
    "bilang_sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14755"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bilang_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing words\n",
    "\n",
    "We'll need a unique index per word to use as the inputs and targets of the networks later. To keep track of all this we will use a helper class called Lang which has word → index (word2index) and index → word (index2word) dictionaries, as well as a count of each word word2count to use to later replace rare words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "UNK_token = 2\n",
    "PAD_token = 3\n",
    "\n",
    "class Vocab:\n",
    "    def __init__(self, tokenizer):\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\", 2: \"UNK\", 3: \"PAD\"}\n",
    "        self.word2index = {v: k for k, v in self.index2word.items()}\n",
    "        self.word2count = {}\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        self.n_words = 4\n",
    "      \n",
    "    def index_words(self, sentence):\n",
    "        tokenized = self.tokenizer(sentence)\n",
    "        for word in tokenized:\n",
    "            self.index_word(word)\n",
    "        return tokenized\n",
    "\n",
    "    def index_word(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "    \n",
    "    def unindex_words(self, indices):\n",
    "        return ' '.join([self.index2word[i] for i in indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalize_string(s):\n",
    "    s = s.lower().strip()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read the data file we will split the file into lines, and then split lines into pairs. Define tokenizers for you languages to split sentences on words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c93b191653be40a3ac9a170d14959529",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "source_tokenizer = tokenize_words\n",
    "target_tokenizer = nltk.tokenize.WordPunctTokenizer().tokenize\n",
    "\n",
    "def read_langs(source_lang, source_tokenizer, target_lang, target_tokenizer, input_file):\n",
    "    corpora = pd.read_csv(input_file, delimiter='\\t')\n",
    "    \n",
    "    source_vocab = Vocab(source_tokenizer)\n",
    "    target_vocab = Vocab(target_tokenizer)\n",
    "    \n",
    "    source_corpora = []\n",
    "    target_corpora = []\n",
    "    for i, row in tqdm(corpora.iterrows()):\n",
    "        source_sent = row['text'+source_lang]\n",
    "        target_sent = row['text'+target_lang]\n",
    "        \n",
    "        source_tokenized = source_vocab.index_words(source_sent)\n",
    "        target_tokenized = target_vocab.index_words(target_sent)\n",
    "        \n",
    "        source_corpora.append(source_tokenized)\n",
    "        target_corpora.append(target_tokenized)\n",
    "    \n",
    "    return source_vocab, target_vocab, list(zip(source_corpora, target_corpora))\n",
    "\n",
    "source_vocab, target_vocab, corpora = read_langs(source_lang, source_tokenizer, target_lang, target_tokenizer, file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering\n",
    "\n",
    "Since there are a lot of example sentences and we want to train something quickly, we'll trim the data set to only relatively short and simple sentences. Here the maximum length is 10 words (that includes punctuation) and we're filtering to sentences that translate to the form \"I am\" or \"He is\" etc. (accounting for apostrophes being removed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 6\n",
    "\n",
    "corpora_filtered = [(source_sent, target_sent) for source_sent, target_sent in corpora\n",
    "                   if len(source_sent) <= MAX_LENGTH and len(target_sent) <= MAX_LENGTH]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9458"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpora_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turning training data into Tensors\n",
    "To train we need to turn the sentences into something the neural network can understand, which of course means numbers. Each sentence will be split into words and turned into a Tensor, where each word is replaced with the index (from the Lang indexes made earlier). While creating these tensors we will also append the EOS token to signal that the sentence is over.\n",
    "\n",
    "A Tensor is a multi-dimensional array of numbers, defined with some type e.g. FloatTensor or LongTensor. In this case we'll be using LongTensor to represent an array of integer indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexes_from_sentence(vocab, sentence):\n",
    "    return [vocab.word2index[word] for word in sentence]\n",
    "\n",
    "def tensor_from_sentence(lang, sentence):\n",
    "    indexes = indexes_from_sentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    indexes.insert(0, SOS_token)\n",
    "    if len(indexes) < 8:\n",
    "        indexes += [PAD_token]*(8-len(indexes))\n",
    "    tensor = torch.LongTensor(indexes)\n",
    "    if USE_CUDA: var = tensor.cuda()\n",
    "    return tensor\n",
    "\n",
    "def tensors_from_pair(source_sent, target_sent):\n",
    "    source_tensor = tensor_from_sentence(source_vocab, source_sent).unsqueeze(1)\n",
    "    target_tensor = tensor_from_sentence(target_vocab, target_sent).unsqueeze(1)\n",
    "    \n",
    "    return (source_tensor, target_tensor)\n",
    "\n",
    "tensors = []\n",
    "for source_sent, target_sent in corpora_filtered:\n",
    "    tensors.append(tensors_from_pair(source_sent, target_sent))\n",
    "    \n",
    "x, y = zip(*tensors)\n",
    "x = torch.transpose(torch.cat(x, dim=-1), 1, 0)\n",
    "y = torch.transpose(torch.cat(y, dim=-1), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder\n",
    "\n",
    "The encoder of a seq2seq network is a RNN that outputs some value for every word from the input sentence. For every input word the encoder outputs a vector and a hidden state, and uses the hidden state for the next input word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, n_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers=n_layers, batch_first=True, bidirectional=True)\n",
    "        \n",
    "    def forward(self, word_inputs, hidden): # word_inputs: (batch_size, seq_length), h: (h_or_c, layer_n_direction, batch, seq_length)\n",
    "        # Note: we run this all at once (over the whole input sequence)\n",
    "        seq_len = len(word_inputs)\n",
    "        \n",
    "        # embedded (batch_size, seq_length, hidden_size)\n",
    "        embedded = self.embedding(word_inputs) \n",
    "        # output (batch_size, seq_length, hidden_size*directions)\n",
    "        # hidden (h: (batch_size, num_layers*directions, hidden_size),\n",
    "        #         c: (batch_size, num_layers*directions, hidden_size))\n",
    "        output, hidden = self.lstm(embedded, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self, batches):\n",
    "        hidden = torch.zeros(2, self.n_layers*2, batches, self.hidden_size)\n",
    "        if USE_CUDA: hidden = hidden.cuda()\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, n_layers=1):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers=n_layers, batch_first=True, bidirectional=False)\n",
    "        \n",
    "    def forward(self, word_inputs, hidden):\n",
    "        # Note: we run this one by one\n",
    "        # embedded (batch_size, 1, hidden_size)\n",
    "        embedded = self.embedding(word_inputs).unsqueeze_(1)\n",
    "        output, hidden = self.lstm(embedded, hidden)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure the Encoder and Decoder model are working (and working together) we'll do a quick test with fake word inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EncoderRNN(\n",
      "  (embedding): Embedding(10, 10)\n",
      "  (lstm): LSTM(10, 10, num_layers=2, batch_first=True, bidirectional=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 20])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_test = EncoderRNN(10, 10, 2)\n",
    "print(encoder_test)\n",
    "\n",
    "encoder_hidden = encoder_test.init_hidden()\n",
    "word_input = torch.LongTensor([[1, 2, 3]])\n",
    "\n",
    "if USE_CUDA:\n",
    "    encoder_test.cuda()\n",
    "    word_input = word_input.cuda()\n",
    "\n",
    "encoder_outputs, encoder_hidden = encoder_test(word_input, encoder_hidden)\n",
    "\n",
    "# (batch_size, seq_length, hidden_size)\n",
    "encoder_outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecoderRNN(\n",
      "  (embedding): Embedding(10, 20)\n",
      "  (lstm): LSTM(20, 20, num_layers=2, batch_first=True)\n",
      ")\n",
      "torch.Size([1, 1, 20]) torch.Size([2, 1, 20]) torch.Size([2, 1, 20])\n",
      "torch.Size([1, 1, 20]) torch.Size([2, 1, 20]) torch.Size([2, 1, 20])\n",
      "torch.Size([1, 1, 20]) torch.Size([2, 1, 20]) torch.Size([2, 1, 20])\n"
     ]
    }
   ],
   "source": [
    "decoder_test = DecoderRNN(10, 20, 2)\n",
    "print(decoder_test)\n",
    "\n",
    "word_inputs = torch.LongTensor([[1, 2, 3]])\n",
    "\n",
    "decoder_hidden_h = encoder_hidden[0].reshape(2, 1, 20)\n",
    "decoder_hidden_c = encoder_hidden[1].reshape(2, 1, 20)\n",
    "\n",
    "if USE_CUDA:\n",
    "    decoder_test.cuda()\n",
    "    word_inputs = word_inputs.cuda()\n",
    "\n",
    "for i in range(3):\n",
    "    input = word_inputs[:, i]\n",
    "    decoder_output, decoder_hidden = decoder_test(input, (decoder_hidden_h, decoder_hidden_c))\n",
    "    decoder_hidden_h, decoder_hidden_c = decoder_hidden\n",
    "    print(decoder_output.size(), decoder_hidden_h.size(), decoder_hidden_c.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Seq2seq(nn.Module):\n",
    "    def __init__(self, input_vocab_size, output_vocab_size, hidden_size):\n",
    "        super(Seq2seq, self).__init__()\n",
    "        \n",
    "        self.encoder = EncoderRNN(input_vocab_size, int(hidden_size/2), 1)\n",
    "        self.decoder = DecoderRNN(output_vocab_size, hidden_size, 1)\n",
    "        \n",
    "        self.W = nn.Linear(hidden_size, output_vocab_size)\n",
    "        self.softmax = nn.Softmax()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "    def forward_train(self, x, y):\n",
    "        batch_size = x.shape[0]\n",
    "        init_hidden = self.encoder.init_hidden(batch_size)\n",
    "        encoder_outputs, encoder_hidden = self.encoder(x, init_hidden)\n",
    "        \n",
    "        decoder_hidden_h = encoder_hidden[0].reshape(1, batch_size, self.hidden_size)\n",
    "        decoder_hidden_c = encoder_hidden[1].reshape(1, batch_size, self.hidden_size)\n",
    "        \n",
    "        H = []\n",
    "        for i in range(y.shape[1]):\n",
    "            input = y[:, i]\n",
    "            decoder_output, decoder_hidden = self.decoder(input, (decoder_hidden_h, decoder_hidden_c))\n",
    "            decoder_hidden_h, decoder_hidden_c = decoder_hidden\n",
    "            # h: (batch_size, vocab_size)\n",
    "            h = self.W(decoder_output.squeeze(1))\n",
    "            # h: (batch_size, vocab_size, 1)\n",
    "            H.append(h.unsqueeze(2))\n",
    "        \n",
    "        # H: (batch_size, vocab_size, seq_len)\n",
    "        return torch.cat(H, dim=2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        init_hidden = self.encoder.init_hidden(batch_size)\n",
    "        encoder_outputs, encoder_hidden = self.encoder(x, init_hidden)\n",
    "        \n",
    "        decoder_hidden_h = encoder_hidden[0].reshape(1, batch_size, self.hidden_size)\n",
    "        decoder_hidden_c = encoder_hidden[1].reshape(1, batch_size, self.hidden_size)\n",
    "        \n",
    "        current_y = SOS_token\n",
    "        result = [current_y]\n",
    "        counter = 0\n",
    "        while current_y != EOS_token and counter < 100:\n",
    "            input = torch.tensor([current_y])\n",
    "            decoder_output, decoder_hidden = self.decoder(input, (decoder_hidden_h, decoder_hidden_c))\n",
    "            decoder_hidden_h, decoder_hidden_c = decoder_hidden\n",
    "            # h: (vocab_size)\n",
    "            h = self.W(decoder_output.squeeze(1)).squeeze(0)\n",
    "            y = self.softmax(h)\n",
    "            _, current_y = torch.max(y, dim=0)\n",
    "            current_y = current_y.item()\n",
    "            result.append(current_y)\n",
    "            counter += 1\n",
    "            \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "model = Seq2seq(source_vocab.n_words, target_vocab.n_words, 60)\n",
    "optim = Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle training indices\n",
    "assert x.shape[0] == y.shape[0]\n",
    "batch_indices = torch.randperm(x.shape[0])\n",
    "# prepare minibatch generator\n",
    "def batch_generator(batch_indices, batch_size):\n",
    "    batches = math.ceil(len(batch_indices)/batch_size)\n",
    "    for i in range(batches):\n",
    "        batch_start = i*batch_size\n",
    "        batch_end = (i+1)*batch_size\n",
    "        if batch_end > len(batch_indices):\n",
    "            yield batch_indices[batch_start:]\n",
    "        else:\n",
    "            yield batch_indices[batch_start:batch_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "# cross_entropy = nn.CrossEntropyLoss()\n",
    "nll = nn.NLLLoss()\n",
    "softmax = nn.Softmax(dim=1)\n",
    "for epoch in range(100):\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(batch_generator(batch_indices, BATCH_SIZE), \n",
    "                      desc='Training epoch {}'.format(epoch+1), total=95):\n",
    "        x_train = x[batch, :] \n",
    "        y_train = y[batch, :]\n",
    "        H = model.forward_train(x_train, y_train)\n",
    "#         loss = cross_entropy(H, y_train)\n",
    "        H = softmax(H)\n",
    "        loss = nll(H, y_train)\n",
    "        print(H[0, :, 2], y[0])\n",
    "        break\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print('Epoch {} training finished, loss: {}'.format(epoch+1, total_loss/95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate(x, model):\n",
    "    y_gen = model(x)\n",
    "    return y_gen\n",
    "\n",
    "x_0, y_0 = x[0], y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,  18,  19,  20,  21,  11,   1,   3])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Вона', 'приймає', 'душ', 'щоранку', '.'],\n",
       " ['Sie', 'duscht', 'jeden', 'Morgen', '.'])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpora_filtered[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SOS Двері відкриті . EOS PAD PAD PAD'"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_vocab.unindex_words(x_train[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SOS Die Tür ist auf . EOS PAD'"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_vocab.unindex_words(y_train[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anatolii.stehnii/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:51: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "y_0_gen = model(x_0.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS'"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_vocab.unindex_words(y_0_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    0,  2617,  2618,    11,     1,     3,     3,     3])"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   0,  157,  755,   29,  317,   13,    1,    3])"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
